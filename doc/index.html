<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>SIGE - Presentación Práctica</title>

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/black.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section data-background="img/bg.jpg" alt="ETSIIT">
					<h1>SIGE - Práctica 2</h1>
					<h3>Clasificación de imágenes</h3>
					<hr>
					<p>Francisco Javier Bolívar Lupiáñez</p>
					<p>Juan Pablo González Casado</p>
					<a href="http://fblupi.es/master_informatica-SIGE/">fblupi.es/master_informatica-SIGE/</a>
				</section>
				<section>
					<section>
						<h1>Exploración de datos</h1>		
					</section>
					<section>
						<h3>Datos de Kaggle</h3>
						<ul>
							<li>Imágenes de cérvix</li>
							<ul>
								<li>Formato: JPG</li>
								<li>Tamaño: 3096x4128</li>
								<li>Peso: 2.5 a 7.5 MB</li>
							</ul>
						</ul>
						<img src="img/imagenes.png" alt="Carpeta con imágenes de cérvix"/>
					</section>
					<section>
						<h3>Test</h3>
						<ul>
							<li>512 imágenes</li>
						</ul>
						<h3>Train</h3>
						<ul>
							<li>~1500 + ~5500 imágenes</li>
						</ul>
					</section>
					<section>
						<h3>Dataset no balanceado</h3>
						<h5>Train</h5>
						<img src="img/num-images-train-dataset.png" alt="Porcentaje de imágenes de cada tipo para el dataset básico"/>
					</section>
					<section>
						<h3>Dataset no balanceado</h3>
						<h5>Train extra</h5>
						<img src="img/num-images-train-extra-dataset.png" alt="Porcentaje de imágenes de cada tipo para el dataset extra"/>
					</section>
				</section>
				<section>
					<section>
						<h1>Pre-procesamiento de datos</h1>		
					</section>
					<section>
						<h3>Imágenes que no corresponde a un cérvix</h3>
						<img height="200px" src="img/3086.jpg" alt="Imágen de una muchacha"/>
						<img height="200px" src="img/4065.jpg" alt="Imágen de motorola"/>
						<img height="200px" src="img/4533.jpg" alt="Imágen de parte de cuerpo que no es cérvix"/>
						<img height="200px" src="img/4367.jpg" alt="Imágen de un cérvix borrosa"/>
					</section>
					<section>
						<h3>Balanceo de clases</h3>
						<h5>Train extra con undersampling</h5>
						<img src="img/num-images-train-extra-balanced-dataset.png" alt="Porcentaje de imágenes de cada tipo para el dataset extra tras aplicarle undersampling"/>
					</section>
				</section>
				<section>
					<section>
						<h1>Técnicas de clasificación</h1>		
					</section>
					<section>
						<h2>Learning from scratch</h2>
						<ul>
							<li>Crear CNN desde cero</li>
							<li>Empezamos con MXNet pero pasamos a Keras</li>
							<li>Seguimos un kernel que habían publicado en Kaggle</li>
						</ul>
					</section>
					<section>
						<h3>Topología</h3>
						<img src="img/kernel-cnn-1.png" alt="Topología kernel básico (I)"/>
						<img src="img/kernel-cnn-2.png" alt="Topología kernel básico (II)"/>
						<img src="img/kernel-cnn-3.png" alt="Topología kernel básico (III)"/>
					</section>
					<section>
						<h2>Fine-tuning</h2>
						<ul>
							<li>Utilizar como base una CNN ya entrenada</li>
							<li>Solo habría que añadir una capa de salida con el número de salidas que queramos</li>
							<li>Keras ofrece:</li>
							<ul>
								<li>Xception</li>
								<li>VGG16</li>
								<li>VGG19</li>
								<li>ResNet50</li>
								<li>InceptionV3</li>
							</ul>
						</ul>
					</section>
					<section>
						<h2>OVO y OVA</h2>
						<ul>
							<li>One vs One (OVO)</li>
							<li>One vs All (OVA)</li>
							<li>Objetivo: Convertir problema multiclase en binario</li>
						</ul>
					</section>
					<section>
						<h2>OVO</h2>
						<ul>
							<li>Construir tres clasificadores:</li>
							<ul>
								<li>1 vs 2</li>
								<li>1 vs 3</li>
								<li>2 vs 3</li>
							</ul>
							<li>Combinar resultados de cada uno:</li>
							<ul>
								<li>Producto normalizado</li>
								<li>Media</li>
							</ul>
						</ul>
					</section>
					<section>
						<h2>OVA</h2>
						<ul>
							<li>Construir tres clasificadores:</li>
							<ul>
								<li>1 vs 2-3</li>
								<li>2 vs 1-3</li>
								<li>3 vs 1-2</li>
							</ul>
							<li>Normalizar salida</li>
						</ul>
					</section>
					<section>
						<h2>Extracción de características</h2>
						<ul>
							<li>Extraer mapa de características de una CNN</li>
							<li>Usar técnicas clásicas de machine learning:</li>
							<ul>
								<li>Random forest</li>
								<li>Boosting</li>
								<li>Support Vector Machine (SVM)</li>
							</ul>
							<li>Podemos encontrarlas en la librería scikit-learn</li>
						</ul>
					</section>
					<section>
						<h2>Ensemblers</h2>
						<ul>
							<li>Usar varios clasificadores</li>
							<ul>
								<li>CNNs</li>
								<li>Técnicas clásicas de machine learning</li>
							</ul>
							<li>Combinar resultados</li>
						</ul>
					</section>
				</section>
			</div>
		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>
			// More info https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				history: true,

				// More info https://github.com/hakimel/reveal.js#dependencies
				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
				]
			});
		</script>
	</body>
</html>
