<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>SIGE - Presentación Práctica</title>

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/black.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section data-background="img/bg.jpg" alt="ETSIIT">
					<h1>SIGE - Práctica 2</h1>
					<h3>Clasificación de imágenes</h3>
					<hr>
					<p>Francisco Javier Bolívar Lupiáñez</p>
					<p>Juan Pablo González Casado</p>
					<a href="http://fblupi.es/master_informatica-SIGE/">fblupi.es/master_informatica-SIGE/</a>
				</section>
				<section>
					<section>
						<h1>Exploración de datos</h1>		
					</section>
					<section>
						<h3>Datos de Kaggle</h3>
						<ul>
							<li>Imágenes de cérvix</li>
							<ul>
								<li>Formato: JPG</li>
								<li>Tamaño: 3096x4128</li>
								<li>Peso: 2.5 a 7.5 MB</li>
							</ul>
						</ul>
						<img src="img/imagenes.png" alt="Carpeta con imágenes de cérvix"/>
					</section>
					<section>
						<h3>Test</h3>
						<ul>
							<li>512 imágenes</li>
						</ul>
						<h3>Train</h3>
						<ul>
							<li>~1500 + ~5500 imágenes</li>
						</ul>
					</section>
					<section>
						<h3>Dataset no balanceado</h3>
						<h5>Train</h5>
						<img src="img/num-images-train-dataset.png" alt="Porcentaje de imágenes de cada tipo para el dataset básico"/>
					</section>
					<section>
						<h3>Dataset no balanceado</h3>
						<h5>Train extra</h5>
						<img src="img/num-images-train-extra-dataset.png" alt="Porcentaje de imágenes de cada tipo para el dataset extra"/>
					</section>
				</section>
				<section>
					<section>
						<h1>Pre-procesamiento de datos</h1>		
					</section>
					<section>
						<h3>Imágenes que no corresponde a un cérvix</h3>
						<img height="200px" src="img/3086.jpg" alt="Imágen de una muchacha"/>
						<img height="200px" src="img/4065.jpg" alt="Imágen de motorola"/>
						<img height="200px" src="img/4533.jpg" alt="Imágen de parte de cuerpo que no es cérvix"/>
						<img height="200px" src="img/4367.jpg" alt="Imágen de un cérvix borrosa"/>
					</section>
					<section>
						<h3>Balanceo de clases</h3>
						<h5>Train extra con undersampling</h5>
						<img src="img/num-images-train-extra-balanced-dataset.png" alt="Porcentaje de imágenes de cada tipo para el dataset extra tras aplicarle undersampling"/>
					</section>
				</section>
				<section>
					<section>
						<h1>Técnicas de clasificación</h1>		
					</section>
					<section>
						<h2>Learning from scratch</h2>
						<ul>
							<li>Crear CNN desde cero</li>
							<li>Empezamos con MXNet pero pasamos a Keras</li>
							<li>Seguimos un kernel que habían publicado en Kaggle que incluía data augmentation</li>
						</ul>
					</section>
					<section>
						<h3>Topología</h3>
						<img src="img/kernel-cnn-1.png" alt="Topología kernel básico (I)"/>
						<img src="img/kernel-cnn-2.png" alt="Topología kernel básico (II)"/>
						<img src="img/kernel-cnn-3.png" alt="Topología kernel básico (III)"/>
					</section>
					<section>
						<h2>Fine-tuning</h2>
						<ul>
							<li>Utilizar como base una CNN ya entrenada</li>
							<li>Solo habría que añadir una capa de salida con el número de salidas que queramos</li>
							<li>Keras ofrece:</li>
							<ul>
								<li>Xception</li>
								<li>VGG16</li>
								<li>VGG19</li>
								<li>ResNet50</li>
								<li>InceptionV3</li>
							</ul>
						</ul>
					</section>
					<section>
						<h2>OVO y OVA</h2>
						<ul>
							<li>One vs One (OVO)</li>
							<li>One vs All (OVA)</li>
							<li>Objetivo: Convertir problema multiclase en binario</li>
						</ul>
					</section>
					<section>
						<h2>OVO</h2>
						<ul>
							<li>Construir tres clasificadores:</li>
							<ul>
								<li>1 vs 2</li>
								<li>1 vs 3</li>
								<li>2 vs 3</li>
							</ul>
							<li>Combinar resultados de cada uno:</li>
							<ul>
								<li>Producto normalizado</li>
								<li>Media</li>
							</ul>
						</ul>
					</section>
					<section>
						<h2>OVA</h2>
						<ul>
							<li>Construir tres clasificadores:</li>
							<ul>
								<li>1 vs 2-3</li>
								<li>2 vs 1-3</li>
								<li>3 vs 1-2</li>
							</ul>
							<li>Normalizar salida</li>
						</ul>
					</section>
					<section>
						<h2>Extracción de características</h2>
						<ul>
							<li>Extraer mapa de características de una CNN</li>
							<li>Usar técnicas clásicas de machine learning:</li>
							<ul>
								<li>Random forest</li>
								<li>Boosting</li>
								<li>Support Vector Machine (SVM)</li>
							</ul>
							<li>Podemos encontrarlas en la librería scikit-learn</li>
						</ul>
					</section>
					<section>
						<h2>Ensemblers</h2>
						<ul>
							<li>Usar varios clasificadores</li>
							<ul>
								<li>CNNs</li>
								<li>Técnicas clásicas de machine learning</li>
							</ul>
							<li>Combinar resultados</li>
						</ul>
					</section>
				</section>
				<section>
					<section>
						<h1>Presentación y discusión de resultados</h1>		
					</section>
					<section>
						<h2>Learning from scratch</h2>
						<ul>
							<li>Comenzamos con MXNet pero predecía el mismo resultado para todas las imágenes</li>
							<li>Nos pasamos a Keras con el script del kernel de Kaggle</li>
							<li>Se usó el conjunto de datos desequilibrado con las imágenes extra</li>
							<li>Se realizaron experimentos variando parámetros</li>
							<li>Red simple -> Entrenamiento relativamente rápido (1 hora máximo)</li>
						</ul>
					</section>
					<section>
						<h3>Estudio del sobre aprendizaje</h3>
						<img src="img/loss-variation-learning-from-scratch.png" alt="Variación del log loss en los distintos conjuntos de datos (train y test) a lo largo de las épocas"/>
					</section>
					<section>
						<h3>Otros experimentos</h3>
						<ul>
							<li>Imágenes 32x32 y 128x128 daban prácticamente el mismo resultado</li>
							<li>Más samples per epoch hacía que se aprendiese (y sobreaprendiese) antes</li>
							<li>Dataset balanceado bajó de ~0.91 a ~0.87</li>
							<li>Red más compleja:</li>
							<ul>
								<li>Dos ciclos más de Conv-Act-Pool</li>
								<li>Más capas Fully Connected</li>
							</ul>
							<li>La red daba peores resultados -> No sabemos hacer una topología buena</li>
						</ul>
					</section>
					<section>
						<h2>Fine tuning</h2>
						<ul>
							<li>Implementación fácil, pero problemas a mansalva:</li>
							<ul>
								<li>No podíamos alojar a 224x224 las 7000 imágenes -> Tuvimos que hacer el undersampling</li>
								<li>Tiempo de cómputo: Una época tardaba entre 40 y 80 minutos</li>
								<li>Se llegaron a entrenar redes durante 13 horas con un ordenador que funcionó con los 8 núcleos al 100% durante 3 días seguidos sin descanso</li> 
							</ul>
						</ul>
					</section>
					<section>
						<h3>Experimentos</h3>
						<ul>
							<li>Se probó con distintas topologías pero las submissions se hicieron solo con ResNet50 porque con el resto no aprendían bien ni el conjunto de train</li>
							<li>Se crearon tres topologías</li>
							<ul>
								<li>Solo una capa Fully Connected para la salida</li>
								<li>Ejemplo de Keras: Una capa Fully Connected intermedia de tamaño 1024</li>
								<li>Ejemplo de Keras: Una capa Fully Connected intermedia de tamaño 512</li> 
							</ul>
						</ul>
					</section>
					<section>
						<h3>Topologías</h3>
						<img src="img/fine-tuning-topology-1.png" alt="Topología fine tuning 1"/>
						<img src="img/fine-tuning-topology-2.png" alt="Topología fine tuning 2"/>
						<img src="img/fine-tuning-topology-3.png" alt="Topología fine tuning 3"/>
						<ul>
							<li>Con la primera no se obtenían buenos resultados</li>
							<li>Con la segunda sobre aprendía muy rápido</li>
						</ul>
					</section>
					<section>
						<h3>Otros experimentos</h3>
						<ul>
							<li>Se probó ajustando batch y samples per epoch como en learning from scratch</li>
							<li>Se probó el entrenamiento en dos fases que se proponía en Keras</li>
							<ul>
								<li>Primera: Se ajustan solo los pesos de las capas añadidas</li>
								<li>Segunda: Se ajustan los pesos de las últimas capas de ResNet50</li>
							</ul>
							<li>Así se obtuvo el mejor resultado ~0.8 en la época 20+40</li>
						</ul>
					</section>
					<section>
						<h3>Estudio del sobre aprendizaje</h3>
						<img src="img/loss-variation-fine-tuning.png" alt="Variación del log loss en los distintos conjuntos de datos (train, val y test) a lo largo de las épocas"/>
					</section>
				</section>
				<section>
					<section>
						<h1>Conclusiones</h1>		
					</section>
					<section>
						<h3>Conclusiones positivas</h3>
						<ul>
							<li>Práctica interesante al ser un problema real</li>
							<li>Gratificante verse en el top 200 de ~850 equipos</li>
							<li>Pero...</li>
						</ul>
					</section>
					<section>
						<h3>Conclusiones negativas</h3>
						<ul>
							<li>Requisitos hardware elevados. Solo servía el ordenador de uno de los dos</li>
							<li>Tiempos muy elevados debido a estos requisitos hardware por no tener GPU</li>
							<li>Los requisitos en memoria nos impedía hacer mucho data augmentation (tuvimos que hacer undersampling en lugar de oversampling para equilibrar las clases)</li>
							<li>Mucho tiempo perdido mientras entrenaban las redes nos impidió probar otras técnicas</li>
							<li>Más momentos de desesperación que de ilusión</li>
						</ul>
					</section>
				</section>
			</div>
		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>
			// More info https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				history: true,

				// More info https://github.com/hakimel/reveal.js#dependencies
				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
				]
			});
		</script>
	</body>
</html>
